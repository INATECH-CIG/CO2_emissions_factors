{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching EUETS and ENTSO E data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This script provides information about the matching mechanism that was used to match the EUETS emission datat with ENTSO E production data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Script setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#helpers\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data directory preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create input, processed and output folders if they don't exist\n",
    "# If the paths are relative, the correspoding folders will be created inside the current working directory.\n",
    "\n",
    "input_directory_path = os.path.join('input')\n",
    "Matching_methode_input_directory_path = os.path.join('input', 'Matching')\n",
    "processed_directory_path = 'processed'\n",
    "output_directory_path = os.path.join('output')\n",
    "\n",
    "os.makedirs(input_directory_path, exist_ok=True)\n",
    "os.makedirs(Matching_methode_input_directory_path, exist_ok=True)\n",
    "os.makedirs(processed_directory_path, exist_ok=True)\n",
    "os.makedirs(output_directory_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matching Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we describe the method that was used to match the ENTSO E power plant names (PowerSystemResourceName) with the ETS plant names (EUTL-ID).\n",
    "\n",
    "Since ENTSO-E and ETS names are not the same in general, a more sophisticated and time expensive approach was used. The general process was:\n",
    "\n",
    "    1.) Using a google search request in order to find out more information about the power plant. For example the address and owner can often be found on the Wikipedia web page.\n",
    "    \n",
    "    2.) The Entso E dataset always provides an EIC number which is the \"Energy Identification code\" for power plants. Googling this code sometimes redirects to a webpage called \"gem.wiki\". It contains similar information like wikipedia but because it is dedicated to fossil fuel projects from time to time more information. (e.g. https://www.gem.wiki/Amfard_power_station)\n",
    "    \n",
    "    3.)Probelm of different names of the power plant: Usually, either the name or the location of a power plant defines its name in the datasets. This will be usually reflected to some point in ENTSO E as well as ETS data, but in very different forms, so no standard algorithm can be applied and manual investigations was done to match such a power plant.\n",
    "    \n",
    "    4.) If names in this two datasets do not coincide at all, another factor was be exploited: The size of the power plant can be used, since most of the time we wanted to find the huge emitter. Since the emission factor is roughly known for each technology, one can specify a range how much this power plant has emitted. (since yearly generation is known) As there are only very few installations with such high emissions, usually less then 10 entries remain in the ETS-database. Further googling then the names of this installations usually reveal what it is referring to, where the plant is and whom it belongs to. using this technique usually provided the result then.\n",
    "    \n",
    "This method was performed for lignite, coal and gas power plants.\n",
    "\n",
    "For Germany an already existing matching list for power plants was used additionally and included in our dataset.\n",
    "Matching List for German power plants with Entso e identifier and the EUTL identifier.\n",
    "Data download form: https://zenodo.org/record/3588418#.XxlZOufgq5h \\\n",
    "\n",
    "File - > Matching_Entso_EUTL_LCPD.csv\n",
    "\n",
    "corresponding Paper: \"Comparing empirical and model-based approaches for calculating dynamic grid emission factors: an application to CO2-minimizing storage dispatch in Germany\"\n",
    "https://linkinghub.elsevier.com/retrieve/pii/S0959652620316358"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading and file preparation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the csv files with the matching information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "lignite_pp = pd.read_csv(os.path.join(Matching_methode_input_directory_path, 'Lignite_pps_matched.csv'), sep = ';', header = 0)\n",
    "coal_pp = pd.read_csv(os.path.join(Matching_methode_input_directory_path, 'Hardcoal_pps_matched.csv'), sep = ';', header = 0)\n",
    "gas_pp = pd.read_csv(os.path.join(Matching_methode_input_directory_path, 'Gas_pps_matched.csv'), sep = ';', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Combine the matching information into one dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches_pp = pd.concat([coal_pp[['PowerSystemResourceName','countrycode','EUTL_ID']],\n",
    "                        gas_pp[['PowerSystemResourceName','countrycode','EUTL_ID']],\n",
    "                        lignite_pp[['PowerSystemResourceName','countrycode','EUTL_ID']]], ignore_index=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Export the matching list. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "Matches_pp.to_csv(processed_directory_path + '/Matching_Entso_EUTL_EU.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PowerSystemResourceName</th>\n",
       "      <th>countrycode</th>\n",
       "      <th>EUTL_ID</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ABOÑO 1</td>\n",
       "      <td>ES</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ABOÑO 2</td>\n",
       "      <td>ES</td>\n",
       "      <td>201.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ABTH7</td>\n",
       "      <td>GB</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ABTH8</td>\n",
       "      <td>GB</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ABTH9</td>\n",
       "      <td>GB</td>\n",
       "      <td>188.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>848</th>\n",
       "      <td>Turów B06</td>\n",
       "      <td>PL</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>849</th>\n",
       "      <td>Weisweiler E</td>\n",
       "      <td>DE</td>\n",
       "      <td>1607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>850</th>\n",
       "      <td>Weisweiler F</td>\n",
       "      <td>DE</td>\n",
       "      <td>1607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>851</th>\n",
       "      <td>Weisweiler G</td>\n",
       "      <td>DE</td>\n",
       "      <td>1607.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>Weisweiler H</td>\n",
       "      <td>DE</td>\n",
       "      <td>1607.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>853 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    PowerSystemResourceName countrycode  EUTL_ID\n",
       "0                   ABOÑO 1          ES    201.0\n",
       "1                   ABOÑO 2          ES    201.0\n",
       "2                     ABTH7          GB    188.0\n",
       "3                     ABTH8          GB    188.0\n",
       "4                     ABTH9          GB    188.0\n",
       "..                      ...         ...      ...\n",
       "848               Turów B06          PL      3.0\n",
       "849            Weisweiler E          DE   1607.0\n",
       "850            Weisweiler F          DE   1607.0\n",
       "851            Weisweiler G          DE   1607.0\n",
       "852            Weisweiler H          DE   1607.0\n",
       "\n",
       "[853 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matches_pp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# this was a check if the other files have more matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lig_2 = pd.read_csv(os.path.join(Matching_methode_input_directory_path, 'Lignite_pps.csv'), sep = ';', header = 0,encoding= 'unicode_escape')\n",
    "#gas_2 = pd.read_csv(os.path.join(Matching_methode_input_directory_path, 'Gas_pps.csv'), sep = ';', header = 0,encoding= 'unicode_escape')\n",
    "#coal_2 = pd.read_csv(os.path.join(Matching_methode_input_directory_path, 'Hardcoal_pps.csv'), sep = ';', header = 0,encoding= 'unicode_escape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Matches_2 = pd.concat([coal[['PowerSystemResourceName','countrycode','EUTL_ID']], gas[['PowerSystemResourceName','countrycode','EUTL_ID']], lig[['PowerSystemResourceName','countrycode','EUTL_ID']]], ignore_index=True)\n",
    "#Matches_2.rename(columns = {'identifier_guess':'EUTL_ID'}, inplace = True)\n",
    "#Matches_2.to_csv(processed_directory_path + '/Matching_Entso_EUTL_EU_2.csv')\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
